<!DOCTYPE html>
<html>
<head>
  <title>Generating Realistic Sound with Prosthetic Hand: A Reinforcement Learning Approach</title>
  <link rel="icon" type="image/x-icon" href="static/images/rilab_logo.jpg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <meta name="google-site-verification" content="yJgIIcMjY8bgeMhrsEe12cErSA2U72dbjkKhiKwMOVs" />
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Generating Realistic Sound with Prosthetic Hand: A Reinforcement Learning Approach</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Taemoon Jeong</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Sankalp Yamsani</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Jooyoung Hong</a><sup>2</sup>,</span>
                    <span class="author-block">
                      <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Kyungseo Park</a><sup>3</sup>,</span>
                      <span class="author-block">
                        <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Joohyung Kim</a><sup>2</sup>,</span>
                        <span class="author-block">
                          <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Sungjoon Choi</a><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Korea University<sup>1</sup>, University of Illinois Urbana-Champaign<sup>2</sup>, DGIST<sup>3</sup><br>IEEE Engineering in Medicine and Biology Society (EMBC) 2024</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this study, we tackle the complex task of enabling prosthetic hands to accurately reproduce sounds, a crucial aspect for distinguishing between different materials through auditory feedback.
            Sound identification, such as discerning a drywall tap from that on a brick wall, significantly enhances the functionality and user experience of prosthetic devices.
            However, achieving this level of auditory feedback in prosthetic hands poses considerable challenges.
            We utilize reinforcement learning (RL) techniques to train prosthetic hands in emulating human-like sound characteristics, focusing on key auditory signals like amplitude and onset timing.
            Our approach integrates a detailed analysis of these sound attributes to direct the prosthetic hand's movements for the sound generation that mimics natural human actions.
            We developed a tailored reward function incorporating amplitude, onset strength, and timing criteria to ensure the prosthetic hand's movements align closely with the intended human-like sound output.          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Pipeline -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Paper Image. -->
      <h2 class="title is-3">Overview</h2>
      <div class="columns">
        <div class="column">
          <div style="text-align: center;"> <!-- 이미지를 가운데 정렬하는 스타일 -->
            <img src="static/images/Figure1.jpg" alt="MY ALT TEXT" width="600" height="auto"/>
          </div>
          <p>
            <b>(A)</b> We first record a human-produced tapping sound and extract key features such as amplitude and onset. These features serve as the reference for the prosthetic hand to learn from and imitate.
            <b>(B)</b> The prosthetic hand then interacts with the environment, in this case, a drum pad, to generate sounds. It learns to adjust its finger movements based on the feedback it receives from the generated sound. We employ a reinforcement learning framework, specifically Proximal Policy Optimization (PPO), to train the hand's control policy. The policy maps the hand's current state to actions that produce the desired tapping motion.
            <b>(C)</b> To guide the learning process, we define a reward function that incorporates multiple sound features. The reward function compares the generated sound with the reference sound in terms of amplitude, onset strength, onset timing, and the number of hits. By maximizing this reward, the prosthetic hand learns to produce tapping sounds that closely resemble the human-produced reference. The policy is iteratively updated based on the earned rewards using the PPO algorithm until convergence.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Pipeline -->

<!-- Hardware Setting -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Hardware Setting</h2>
      <div class="columns">
        <div class="column">
          <p>
            We used PSYONIC Ability Hand, a prosthetic hand with six degrees of freedom.
            The hand was mounted on a 6-DOF PAPRAS robot arm, and one finger was controlled while the arm was held in a fixed pose.
            The sound was recorded using a ZOOM H6 recorder for 1-second intervals.
            Only mono sound information was used, despite the device's stereo capabilities.
            An 8-inch Eastar drum practice pad served as the tapping object, struck directly by the Ability hand to produce sound.
            The prosthetic hand performs a tapping motion while the position of its wrist and the height of the drum pad are fixed and generate sound.
          </p> <br>
            <div class="columns is-centered has-text-centered">
              <div class="column is-three-fifths">
                <img src="static/images/Figure2.jpg" alt="MY ALT TEXT" width="600" height="auto"/>
                  <p>
                    The hardware setup includes PSYONIC Ability Hand, mounted on a 6-DOF PAPRAS robot arm.
                    Sound recording is performed using a ZOOM H6 recorder.
                    An 8-inch Eastar Drum Practice Pad is utilized as the tapping object.
                  </p>
              </div>
            </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Hardware Setting -->

<!-- Experimental Results -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Experimental Results</h2>
      
      <!-- Tapping Motion Sequence in full-width -->
      <div class="columns">
        <div class="column is-full">
          <p class="title is-4">Tapping Motion Sequence</p>
          <img src="static/images/Figure6.jpg" alt="Tapping Motion Sequence" width="100%" height="auto"/>
          <p>
            Snapshot of prosthetic hand movements for sound generation. 
            (Top) The movement of the trained prosthetic hand when given a single beat sound of one-second duration. 
            (Bottom) The movement of the trained prosthetic hand when given a double beat sound of one-second duration.
          </p>
        </div>
      </div>
      
      <!-- Other three items in three columns -->
      <div class="columns">
        <div class="column is-one-third">
          <p class="title is-4">Learning Curve</p>
          <img src="static/images/Figure3.jpg" alt="Learning Curve" width="81%" height="auto"/>
          <p>
            The learning curve of a prosthetic hand to make tapping sounds, single-beat and double-beats. 
            The blue line is the smoothed reward, and the light blue area indicates the variance.
          </p>
        </div>
    
        <div class="column is-one-third">
          <p class="title is-4">Waveform Comparison</p>
          <img src="static/images/Figure4.jpg" alt="Waveform Comparison" width="80%" height="auto"/>
          <p>
            The waveforms of the reference sound and the generated sound for both single beats (Top) and double beats (Bottom). 
            While the generated sound exhibits some motor noise, the two waveforms are remarkably well aligned along the time axis.
          </p>
        </div>
    
        <div class="column is-one-third">
          <p class="title is-4">Onset Strength and Timing</p>
          <img src="static/images/Figure5.jpg" alt="Onset Strength and Timing" width="100%" height="auto"/>
          <p>
            The onset strength and timing for both the reference sound and the generated sound in single beats (Top) and double beats (Bottom). 
            The timing difference between the two beats in the generated sound closely aligns with the timing difference in the reference.
          </p>
        </div>
      </div>
      
    </div>
  </div>
</section>
<!-- End Experimental Results -->


<!-- Demo Video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Demo Video</h2>
      <div class="columns is-centered">
        <div class="column is-half">
          <video width="1000" height="auto" controls>
            <source src="static/videos/Demo_vid.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video> 
        </div>
      </div>
    
      <p>
        This video demonstrates the learning process of the prosthetic hand for generating single beat tapping sounds on a drum pad. 
        It showcases the hand's motion from the initial stages of learning to the final learned policy.
      </p>
    
      <p>  
        Observe how the hand's finger movements gradually improve over the course of training. 
        At the beginning, the tapping motion may appear erratic and inconsistent. 
        However, as the learning progresses, the hand learns to adjust its finger trajectories and timing to create a single beat pattern that closely resembles the reference sound.
      </p>
    
      <p>
        By the end of the training, the prosthetic hand exhibits a smooth and precise tapping motion, accurately reproducing the desired single beat sound on the drum pad.
        This demonstration highlights the effectiveness of our reinforcement learning approach in enabling the prosthetic hand to learn and generate realistic tapping sounds.
      </p>
    </div>
  </div>
</section>
<!-- End Demo Video -->

<!-- Paper -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Paper</h2>

      <iframe  src="static/pdfs/Final_EMBC_2024.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
