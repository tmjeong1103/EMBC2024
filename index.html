<!DOCTYPE html>
<html>
<head>
  <title>Generating Realistic Sound with Prosthetic Hand: A Reinforcement Learning Approach</title>
  <link rel="icon" type="image/x-icon" href="static/images/logo.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Generating Realistic Sound with Prosthetic Hand: A Reinforcement Learning Approach</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Taemoon Jeong</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Sankalp Yamsani</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Jooyoung Hong</a><sup>2</sup>,</span>
                    <span class="author-block">
                      <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Kyungseo Park</a><sup>3</sup>,</span>
                      <span class="author-block">
                        <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Joohyung Kim</a><sup>2</sup>,</span>
                        <span class="author-block">
                          <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Sungjoon Choi</a><sup>1</sup>,</span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Korea University<sup>1</sup>, University of Illinois Urbana-Champaign<sup>2</sup>, DGIST<sup>3</sup><br>IEEE Engineering in Medicine and Biology Society (EMBC) 2024</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this study, we tackle the complex task of enabling prosthetic hands to accurately reproduce sounds, a crucial aspect for distinguishing between different materials through auditory feedback.
            Sound identification, such as discerning a drywall tap from that on a brick wall, significantly enhances the functionality and user experience of prosthetic devices.
            However, achieving this level of auditory feedback in prosthetic hands poses considerable challenges.
            We utilize reinforcement learning (RL) techniques to train prosthetic hands in emulating human-like sound characteristics, focusing on key auditory signals like amplitude and onset timing.
            Our approach integrates a detailed analysis of these sound attributes to direct the prosthetic hand's movements for the sound generation that mimics natural human actions.
            We developed a tailored reward function incorporating amplitude, onset strength, and timing criteria to ensure the prosthetic hand's movements align closely with the intended human-like sound output.          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Pipeline -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Paper Image. -->
      <h2 class="title is-3">Overview</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <img src="static/images/Figure1.jpg" alt="MY ALT TEXT" width="600" height="auto"/>
          <p>
            (<b>A</b>) Listening to human-produced sound and extracting sound features such as amplitude and onset.
            (<b>B</b>) Interaction with the object and sound generation according to the action of the prosthetic hand.
            (<b>C</b>) Calculate the reward, including amplitude, onset, timing, and hit reward from the extracted sound information and recorded interactive sound.          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Pipeline -->

<!-- Hardware Setting -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Hardware Setting</h2>
      <div class="columns">
        <div class="column">
          <p>
            We used PSYONIC Ability Hand, a prosthetic hand with six degrees of freedom.
            The hand was mounted on a 6-DOF PAPRAS robot arm, and one finger was controlled while the arm was held in a fixed pose.
            The sound was recorded using a ZOOM H6 recorder for 1-second intervals.
            Only mono sound information was used, despite the device's stereo capabilities.
            An 8-inch Eastar drum practice pad served as the tapping object, struck directly by the Ability hand to produce sound.
            The prosthetic hand performs a tapping motion while the position of its wrist and the height of the drum pad are fixed and generate sound.
          </p> <br>
            <div class="columns is-centered has-text-centered">
              <div class="column is-three-fifths">
                <img src="static/images/Figure2.jpg" alt="MY ALT TEXT" width="600" height="auto"/>
                  <p>
                    The hardware setup includes PSYONIC Ability Hand, mounted on a 6-DOF PAPRAS robot arm.
                    Sound recording is performed using a ZOOM H6 recorder.
                    An 8-inch Eastar Drum Practice Pad is utilized as the tapping object.
                  </p>
              </div>
            </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Hardware Setting -->

<!-- Experimental Results -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Experimental Results</h2>
      <div class="columns is-centered">
        <div class="column is-half">
          <p class="title is-4">Learning Curve</p>
          <img src="static/images/Figure3.jpg" alt="Learning Curve" width="500" height="auto"/>
          <p>
            The learning curve of a prosthetic hand to make tapping sounds, single-beat and double-beats. 
            The blue line is the smoothed reward, and the light blue area indicates the variance.
          </p>
        </div>
    
        <div class="column is-half">
          <p class="title is-4">Waveform Comparison</p>
          <img src="static/images/Figure4.jpg" alt="Waveform Comparison" width="500" height="auto"/>
          <p>
            The waveforms of the reference sound and the generated sound for both single beats (Top) and double beats (Bottom). 
            While the generated sound exhibits some motor noise, the two waveforms are remarkably well aligned along the time axis.
          </p>
        </div>
      </div>
    
      <div class="columns is-centered">
        <div class="column is-half">
          <p class="title is-4">Onset Strength and Timing</p>
          <img src="static/images/Figure5.jpg" alt="Onset Strength and Timing" width="500" height="auto"/>
          <p>
            The onset strength and timing for both the reference sound and the generated sound in single beats (Top) and double beats (Bottom). 
            The timing difference between the two beats in the generated sound closely aligns with the timing difference in the reference.
          </p>
        </div>
    
        <div class="column is-half">
          <p class="title is-4">Tapping Motion Sequence</p>
          <img src="static/images/Figure6.jpg" alt="Tapping Motion Sequence" width="650" height="auto"/>
          <p>
            Snapshot of prosthetic hand movements for sound generation. 
            (Top) The movement of the trained prosthetic hand when given a single beat sound of one-second duration. 
            (Bottom) The movement of the trained prosthetic hand when given a double beat sound of one-second duration.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Experimental Results -->

<!-- Demo Video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Demo Video</h2>
      <div class="columns is-centered">
        <div class="column is-half">
          <video width="1000" height="auto" controls>
            <source src="static/videos/Demo_vid.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video> 
        </div>
      </div>
    
      <p>
        This video demonstrates the learning process of the prosthetic hand for generating single beat tapping sounds on a drum pad. 
        It showcases the hand's motion from the initial stages of learning to the final learned policy.
      </p>
    
      <p>  
        Observe how the hand's finger movements gradually improve over the course of training. 
        At the beginning, the tapping motion may appear erratic and inconsistent. 
        However, as the learning progresses, the hand learns to adjust its finger trajectories and timing to create a single beat pattern that closely resembles the reference sound.
      </p>
    
      <p>
        By the end of the training, the prosthetic hand exhibits a smooth and precise tapping motion, accurately reproducing the desired single beat sound on the drum pad.
        This demonstration highlights the effectiveness of our reinforcement learning approach in enabling the prosthetic hand to learn and generate realistic tapping sounds.
      </p>
    </div>
  </div>
</section>
<!-- End Demo Video -->

<!-- Paper -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Paper</h2>

      <iframe  src="static/pdfs/Final_EMBC_2024.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
